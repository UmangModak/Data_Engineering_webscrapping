{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8clfVZ3-QGB",
        "outputId": "299eee12-d6cd-45ff-820d-cc72384d2dfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to Richmond_data.html\n",
            "Data saved to Bakersfield_data.html\n",
            "Data saved to Wasco_data.html\n",
            "Data saved to Eureka_data.html\n",
            "Data saved to Arcata_data.html\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# Define URLs for data sources\n",
        "sources = {\n",
        "    \"Richmond\": \"https://www.ci.richmond.ca.us/1404/Major-Projects\",\n",
        "    \"Bakersfield\": \"https://www.bakersfieldcity.us/518/Projects-Programs\",\n",
        "    \"Wasco\": \"https://www.cityofwasco.org/311/Current-Projects\",\n",
        "    \"Eureka\": \"https://www.eurekaca.gov/744/Upcoming-Projects\",\n",
        "    \"Arcata\": \"https://www.cityofarcata.org/413/Current-City-Construction-Projects\",\n",
        "    # Add more sources as needed\n",
        "}\n",
        "\n",
        "# Function to extract data from each source\n",
        "def extract_data(source_url):\n",
        "    # Example: Extract HTML content\n",
        "    response = requests.get(source_url)\n",
        "    if response.status_code == 200:\n",
        "        return response.text\n",
        "    else:\n",
        "        print(f\"Failed to retrieve data from {source_url}\")\n",
        "        return None\n",
        "\n",
        "# Function to transform data into a common format (e.g., DataFrame)\n",
        "def transform_data(html_content):\n",
        "    # Example: Extract relevant information from HTML content\n",
        "    # You would need to use BeautifulSoup or similar libraries for parsing HTML\n",
        "    # Here, I'm just returning the raw HTML content as an example\n",
        "    return html_content\n",
        "\n",
        "# Function to load transformed data into a database or file\n",
        "def load_data(data, filename):\n",
        "    # Example: Save HTML content to a file\n",
        "    with open(filename, \"w\") as file:\n",
        "        file.write(data)\n",
        "    print(f\"Data saved to {filename}\")\n",
        "\n",
        "def main():\n",
        "    for source, url in sources.items():\n",
        "        # Extract data from each source\n",
        "        html_content = extract_data(url)\n",
        "\n",
        "        # Transform extracted data\n",
        "        transformed_data = transform_data(html_content)\n",
        "\n",
        "        # Load transformed data\n",
        "        load_data(transformed_data, f\"{source}_data.html\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N6FZD13BlSo",
        "outputId": "c0be8503-6b36-4537-bb7b-8d875b2eb704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfRszg1RC2DM",
        "outputId": "e7a6c66b-aa04-42f2-fd8a-0fd5918ed186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               title\n",
            "0   Major Projects | Richmond, CA - Official Website\n",
            "1  Projects & Programs | Bakersfield, CA - Offici...\n",
            "2                       Current Projects | Wasco, CA\n",
            "3                     Upcoming Projects | Eureka, CA\n",
            "4    Current City Construction Projects | Arcata, CA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Define data sources\n",
        "sources = {\n",
        "    \"Richmond\": \"https://www.ci.richmond.ca.us/1404/Major-Projects\",\n",
        "    \"Bakersfield\": \"https://www.bakersfieldcity.us/518/Projects-Programs\",\n",
        "    \"Wasco\": \"https://www.cityofwasco.org/311/Current-Projects\",\n",
        "    \"Eureka\": \"https://www.eurekaca.gov/744/Upcoming-Projects\",\n",
        "    \"Arcata\": \"https://www.cityofarcata.org/413/Current-City-Construction-Projects\",\n",
        "    \"Mckinleyville\": \"https://www.mckinleyvillecsd.com/news-and-project-updates\",\n",
        "    \"San Rafael\": \"https://www.cityofsanrafael.org/major-planning-projects-2/\",\n",
        "    \"Mill Valley\": \"https://www.cityofmillvalley.org/258/Projects\",\n",
        "    \"Riverside\": \"https://riversideca.gov/utilities/projects\",\n",
        "    \"Moreno Valley\": \"https://www.moval.org/cdd/documents/about-projects.html\",\n",
        "    \"Sacramento\": \"http://www.cityofsacramento.org/public-works/engineering-services/projects\",\n",
        "    \"Citrus Heights\": \"https://www.citrusheights.net/292/Current-Projects\",\n",
        "    \"Elk Grove\": \"https://www.elkgrovecity.org/southeast-policy-area/development-projects\",\n",
        "    \"Petaluma\": \"https://cityofpetaluma.org/planning-projects/\",\n",
        "    \"Santa Rosa\": \"https://www.srcity.org/3212/Current-Projects\",\n",
        "    \"Santa Maria\": \"https://www.santamariagroup.com/projects\",\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Add more sources as needed\n",
        "}\n",
        "\n",
        "# Function to scrape data from a single source\n",
        "def scrape_data(source_url):\n",
        "    response = requests.get(source_url)\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        # Your scraping logic here\n",
        "        # For example, to extract title\n",
        "        title = soup.find('title').text.strip()\n",
        "        # Extract other data as needed\n",
        "        return {\"title\": title}  # Return scraped data as a dictionary\n",
        "    else:\n",
        "        print(f\"Failed to scrape data from {source_url}\")\n",
        "        return None\n",
        "\n",
        "# Function to standardize the scraped data\n",
        "def standardize_data(scraped_data):\n",
        "    # Your standardization logic here\n",
        "    # For demonstration, just return the scraped data\n",
        "    return scraped_data\n",
        "\n",
        "# Function to store data in a DataFrame and save to CSV\n",
        "def save_to_csv(data):\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv('scraped_data.csv', index=False)\n",
        "    print(\"Data saved to 'scraped_data.csv'\")\n",
        "\n",
        "# Function to automate the scraping and standardization processes\n",
        "def automate_data_processing(sources):\n",
        "    scraped_data = []\n",
        "    for source, url in sources.items():\n",
        "        print(f\"Scraping data from {source}...\")\n",
        "        data = scrape_data(url)\n",
        "        if data:\n",
        "            standardized_data = standardize_data(data)\n",
        "            scraped_data.append(standardized_data)\n",
        "            print(f\"Data scraped and standardized from {source}\")\n",
        "        else:\n",
        "            print(f\"Failed to scrape data from {source}\")\n",
        "        # Add a small delay to avoid overwhelming the servers\n",
        "        time.sleep(2)\n",
        "\n",
        "    save_to_csv(scraped_data)\n",
        "\n",
        "# Execute the automation process\n",
        "automate_data_processing(sources)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCVRUDvoDDRb",
        "outputId": "e7280996-7b64-4fab-8c91-4d5cd20d996d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping data from Richmond...\n",
            "Data scraped and standardized from Richmond\n",
            "Scraping data from Bakersfield...\n",
            "Data scraped and standardized from Bakersfield\n",
            "Scraping data from Wasco...\n",
            "Data scraped and standardized from Wasco\n",
            "Scraping data from Eureka...\n",
            "Data scraped and standardized from Eureka\n",
            "Scraping data from Arcata...\n",
            "Data scraped and standardized from Arcata\n",
            "Scraping data from Mckinleyville...\n",
            "Data scraped and standardized from Mckinleyville\n",
            "Scraping data from San Rafael...\n",
            "Data scraped and standardized from San Rafael\n",
            "Scraping data from Mill Valley...\n",
            "Data scraped and standardized from Mill Valley\n",
            "Scraping data from Riverside...\n",
            "Data scraped and standardized from Riverside\n",
            "Scraping data from Moreno Valley...\n",
            "Data scraped and standardized from Moreno Valley\n",
            "Scraping data from Sacramento...\n",
            "Data scraped and standardized from Sacramento\n",
            "Scraping data from Citrus Heights...\n",
            "Data scraped and standardized from Citrus Heights\n",
            "Scraping data from Elk Grove...\n",
            "Data scraped and standardized from Elk Grove\n",
            "Scraping data from Petaluma...\n",
            "Data scraped and standardized from Petaluma\n",
            "Scraping data from Santa Rosa...\n",
            "Data scraped and standardized from Santa Rosa\n",
            "Scraping data from Santa Maria...\n",
            "Data scraped and standardized from Santa Maria\n",
            "Data saved to 'scraped_data.csv'\n"
          ]
        }
      ]
    }
  ]
}